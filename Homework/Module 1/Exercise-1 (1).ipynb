{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64deb005-9478-4bae-8568-e03828daefe4",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Exercise 01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e5667b8-f52d-475c-a5d3-bc8b61914ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c5112a-375e-474d-80db-4b5e863f63a5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## PART A - NumPy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540976e6-5b65-4250-a8dd-5fb2768b98f6",
   "metadata": {},
   "source": [
    "* **(7 points)** Create a random array with 1000 rows and 5 columns by generating the columns one at a time and then concatenating them to create the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f55f469-53d6-410c-81d7-35fd8e7e39ea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.75163551 0.21517617 0.97137068 0.29110584 0.88552509]\n",
      " [0.58144467 0.9275708  0.21388838 0.80979618 0.34296785]\n",
      " [0.4715218  0.98621432 0.62509873 0.80685944 0.66919438]\n",
      " ...\n",
      " [0.76603243 0.50730121 0.98169809 0.77786192 0.31158031]\n",
      " [0.00168853 0.96432945 0.4210681  0.78215753 0.59215648]\n",
      " [0.1848045  0.31009975 0.63434073 0.83466619 0.04476396]]\n",
      "(1000, 5)\n"
     ]
    }
   ],
   "source": [
    "rand_array = np.empty((1000,0)) #empty array that can fit 1000 rows\n",
    "for i in range(0,5): #loop through 5 times\n",
    "    col = np.random.rand(1000,1) #generate random 1000 row column\n",
    "    rand_array = np.hstack((rand_array, col)) #append to array\n",
    "print(rand_array)\n",
    "print(rand_array.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e1c1d9-2777-4119-bee7-eade7c1f3b5d",
   "metadata": {},
   "source": [
    "* **(4 points)** Shuffle the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4b2c75e-5355-45f3-b182-575f54e62840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.49761724 0.52775188 0.79832255 0.64008884 0.64773076]\n",
      " [0.53516761 0.8508546  0.4340267  0.0434548  0.94175421]\n",
      " [0.96158402 0.85893433 0.53725214 0.67354171 0.73713656]\n",
      " ...\n",
      " [0.48931001 0.10775135 0.04362865 0.63282679 0.8103825 ]\n",
      " [0.87237714 0.45394154 0.33883746 0.14610274 0.24224143]\n",
      " [0.34235562 0.78537505 0.32143264 0.02888991 0.93546883]]\n"
     ]
    }
   ],
   "source": [
    "np.random.shuffle(rand_array)\n",
    "print(rand_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22810d7b-aa04-4083-9356-af786dbf6ad6",
   "metadata": {},
   "source": [
    "* **(5 points)** Split it using a 60/25/15 split into three sets: training, validation and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3f96ba5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rand_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "529dbacd-b1ad-48e2-be97-f0a36f0f5c85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(600, 5)\n",
      "(250, 5)\n",
      "(150, 5)\n"
     ]
    }
   ],
   "source": [
    "#get split indexes from array length and fractions\n",
    "array_len = len(rand_array)\n",
    "train_split = int(.6*array_len)\n",
    "validation_split = int(.25*array_len)\n",
    "test_split = int(.15*array_len)\n",
    "\n",
    "#split array using indexes\n",
    "rand_array_train = rand_array[:train_split]\n",
    "rand_array_valid = rand_array[train_split:train_split+validation_split]\n",
    "rand_array_test = rand_array[train_split+validation_split:] #take all lefover rows\n",
    "\n",
    "print(rand_array_train.shape)\n",
    "print(rand_array_valid.shape)\n",
    "print(rand_array_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c324f7a-ef29-4cb4-b4fa-b38fade159ee",
   "metadata": {},
   "source": [
    "* **(4 points)** Standardize every column in the training set by subtracting every column by its mean and dividing the result by its standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45ccafb3-f283-497b-ab60-7d085aadd501",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.04206556,  0.06481263,  1.04605507,  0.52035035,  0.56201644],\n",
       "       [ 0.17022976,  1.17797931, -0.19971905, -1.55713738,  1.56422233],\n",
       "       [ 1.62564327,  1.20581592,  0.15327858,  0.63683368,  0.86676431],\n",
       "       ...,\n",
       "       [ 0.77146973, -1.45257558,  0.73172278, -1.47960532, -1.60612171],\n",
       "       [ 0.94382788,  0.97219173,  0.31426742,  0.46573314,  0.45704933],\n",
       "       [ 1.73108852,  0.24465355,  0.02743186,  0.63906646,  0.9572767 ]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#save these values for use in validation and test\n",
    "train_mean = rand_array_train.mean(axis = 0) #one row per column\n",
    "train_std = rand_array_train.std(axis = 0)\n",
    "\n",
    "#full array transformation\n",
    "rand_array_train = (rand_array_train-train_mean)/train_std \n",
    "rand_array_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e81e553-72a0-4e99-a34c-34297e17ab06",
   "metadata": {},
   "source": [
    "* **(2 points)** Do the same with validation and test sets but using the mean and standard deviation from the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50b79f66-fe37-4761-b152-3c0cc5c43a8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.64228441  0.90084778  1.44224602  0.79153311  0.30810123]\n",
      " [-1.55037338  0.48138995  1.38535553 -1.11576702  0.95825463]\n",
      " [-1.22722177  0.027836   -1.49171089  1.16357783 -0.55510121]\n",
      " [ 1.70161713  0.81498912  0.47194229  0.57696734 -0.10579517]\n",
      " [-0.17895298 -0.64346033  0.72452068  0.18723061  0.47592382]]\n",
      "\n",
      "[[-1.50089139 -1.3162285  -1.17801249  0.80106971 -1.29437128]\n",
      " [ 1.30653272  0.92119211 -1.37425296 -0.43313461 -1.07125162]\n",
      " [ 0.09632107  1.63060457 -0.89502149  1.17864368 -0.30801838]\n",
      " [ 0.90906226 -1.01208598  1.6378238  -0.69481314  1.37256024]\n",
      " [ 0.88503406  1.13112395  1.21906298 -0.62606017 -0.09074497]]\n"
     ]
    }
   ],
   "source": [
    "#apply same transformation for valid and test\n",
    "rand_array_valid = (rand_array_valid-train_mean)/train_std\n",
    "rand_array_test = (rand_array_test-train_mean)/train_std\n",
    "\n",
    "print(rand_array_valid[:5])\n",
    "print()\n",
    "print(rand_array_test[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93bdde8f-1373-45a6-aa03-83cc37e10c0c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## PART B - PyTorch\n",
    "This is a repetition of PART A but using PyTorch instead."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628bfd51-c9f2-4eef-b46e-8f33406619e8",
   "metadata": {},
   "source": [
    "* **(5 points)** Create a tensor  with 1000 rows and 5 columns by generating the columns one at a time and then concatenating them to create the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce26206a-ba73-459b-9b22-7535bcab1c27",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8003, 0.8601, 0.3913, 0.7795, 0.7726],\n",
      "        [0.3377, 0.3450, 0.4437, 0.7451, 0.6461],\n",
      "        [0.3286, 0.5863, 0.2979, 0.7579, 0.6151],\n",
      "        ...,\n",
      "        [0.5793, 0.7584, 0.8764, 0.5330, 0.9151],\n",
      "        [0.4425, 0.7987, 0.5851, 0.8206, 0.2822],\n",
      "        [0.7041, 0.1093, 0.5218, 0.5278, 0.8563]])\n",
      "torch.Size([1000, 5])\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,5): #loop through 5 times\n",
    "    if i == 0: #for the first column\n",
    "        col = torch.rand(1000,1) #generate random column\n",
    "        rand_torch = col #create the base array based off first column\n",
    "    else:  #for columns 2-5\n",
    "        col = torch.rand(1000,1) #generate random column\n",
    "        rand_torch = torch.cat((rand_torch, col), dim = 1) #append to exisitng tensor\n",
    "print(rand_torch)\n",
    "print(rand_torch.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b5757b-02eb-4b23-878b-28cf6c49f0fe",
   "metadata": {},
   "source": [
    "* **(4 points)** Shuffle the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec769f4a-b42d-49d6-aa3f-c8d96e058200",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6273, 0.0331, 0.1148, 0.8788, 0.3910],\n",
       "        [0.8188, 0.5117, 0.5546, 0.0967, 0.3220],\n",
       "        [0.3013, 0.2081, 0.4553, 0.0159, 0.9733],\n",
       "        ...,\n",
       "        [0.5086, 0.8803, 0.9926, 0.2728, 0.8364],\n",
       "        [0.9982, 0.1591, 0.8063, 0.5979, 0.3852],\n",
       "        [0.3650, 0.9943, 0.3072, 0.9042, 0.6633]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shuffled_index = torch.randperm(rand_torch.shape[0]) #use randperm() function to generate random samples within length of tensor\n",
    "rand_torch = rand_torch[shuffled_index]\n",
    "rand_torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d54f34-3468-461e-be66-4459fd455398",
   "metadata": {},
   "source": [
    "* **(5 points)** Split it using a 60/25/15 split into three sets: training, validation and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "372a40a2-6a20-48b5-8fe7-90bc1b1d2628",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([600, 5])\n",
      "torch.Size([250, 5])\n",
      "torch.Size([150, 5])\n"
     ]
    }
   ],
   "source": [
    "#get split indexes from tensor length and fractions\n",
    "torch_len = len(rand_torch)\n",
    "train_split = int(.6*torch_len)\n",
    "validation_split = int(.25*torch_len)\n",
    "test_split = int(.15*torch_len)\n",
    "\n",
    "#split tensor using indexes\n",
    "rand_torch_train = rand_torch[:train_split]\n",
    "rand_torch_valid = rand_torch[train_split:train_split+validation_split]\n",
    "rand_torch_test = rand_torch[train_split+validation_split:] #take all lefover rows\n",
    "\n",
    "print(rand_torch_train.shape)\n",
    "print(rand_torch_valid.shape)\n",
    "print(rand_torch_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17555f33-aa34-4c76-8f0e-979f9603cd56",
   "metadata": {},
   "source": [
    "* **(4 points)** Standardize every column in the training set by subtracting every column by its mean and dividing the result by its standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "65c4b9f9-dec8-4665-afc5-777719b071c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.4127, -1.6237, -1.3435,  1.2356, -0.4561],\n",
       "        [ 1.0786,  0.0522,  0.2081, -1.4005, -0.6937],\n",
       "        [-0.7210, -1.0110, -0.1423, -1.6729,  1.5480],\n",
       "        ...,\n",
       "        [ 0.7477,  0.4489,  1.7786,  0.6790,  1.4353],\n",
       "        [-0.4717, -1.3077, -0.8961, -0.4929,  1.3076],\n",
       "        [-1.2894, -0.9482,  1.5418, -0.3850,  0.3521]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#save these values for use in validation and test\n",
    "train_mean = rand_torch_train.mean(axis = 0) #one row per column\n",
    "train_std = rand_torch_train.std(axis = 0)\n",
    "\n",
    "#full array transformation\n",
    "rand_torch_train = (rand_torch_train-train_mean)/train_std \n",
    "rand_torch_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff25398-61aa-49ce-aa9b-ed916734888e",
   "metadata": {},
   "source": [
    "* **(2 points)** Do the same with validation and test sets but using the mean and standard deviation from the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "134bd554-2766-45d6-bc1f-fcc949c26216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.5452, -1.0768, -1.3115, -1.2541, -0.8374],\n",
      "        [ 0.2368, -1.5803,  0.0916,  0.4575, -1.1198],\n",
      "        [-0.5174,  1.0873,  0.6191,  0.0557,  0.1042],\n",
      "        [ 1.4058, -0.1170, -0.9441,  0.7785, -0.1161],\n",
      "        [-1.0550, -0.3819,  0.0763,  1.1148,  0.5924]])\n",
      "\n",
      "tensor([[-0.5584,  0.1022,  1.2540,  0.2453, -1.5912],\n",
      "        [-0.5541, -1.4701, -0.8711, -0.6473,  1.0272],\n",
      "        [-0.6221,  0.5215,  1.0674, -0.3654,  0.6930],\n",
      "        [ 0.7686,  0.7450, -0.8908, -1.6625,  0.6549],\n",
      "        [-1.0806, -0.2992, -1.5704,  0.1151,  0.1925]])\n"
     ]
    }
   ],
   "source": [
    "#apply same transformation for valid and test\n",
    "rand_torch_valid = (rand_torch_valid-train_mean)/train_std\n",
    "rand_torch_test = (rand_torch_test-train_mean)/train_std\n",
    "\n",
    "print(rand_torch_valid[:5])\n",
    "print()\n",
    "print(rand_torch_test[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0dab4a-84cb-4b3e-a927-8f5116aa79c9",
   "metadata": {},
   "source": [
    "## PART C - Pandas\n",
    "* **(6 points)** Take the 1000-row dataset you created in the Numpy part and create a DataFrame with it. Give the columns the names `x1` to `x5`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4f65dbd3-8d44-4780-a43a-f2e4bb593861",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.497617</td>\n",
       "      <td>0.527752</td>\n",
       "      <td>0.798323</td>\n",
       "      <td>0.640089</td>\n",
       "      <td>0.647731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.535168</td>\n",
       "      <td>0.850855</td>\n",
       "      <td>0.434027</td>\n",
       "      <td>0.043455</td>\n",
       "      <td>0.941754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.961584</td>\n",
       "      <td>0.858934</td>\n",
       "      <td>0.537252</td>\n",
       "      <td>0.673542</td>\n",
       "      <td>0.737137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.372617</td>\n",
       "      <td>0.081365</td>\n",
       "      <td>0.926203</td>\n",
       "      <td>0.853181</td>\n",
       "      <td>0.240759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.508953</td>\n",
       "      <td>0.706298</td>\n",
       "      <td>0.066575</td>\n",
       "      <td>0.465725</td>\n",
       "      <td>0.265353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>0.982321</td>\n",
       "      <td>0.107887</td>\n",
       "      <td>0.367223</td>\n",
       "      <td>0.103049</td>\n",
       "      <td>0.685719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>0.711992</td>\n",
       "      <td>0.306617</td>\n",
       "      <td>0.421300</td>\n",
       "      <td>0.709578</td>\n",
       "      <td>0.532664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>0.489310</td>\n",
       "      <td>0.107751</td>\n",
       "      <td>0.043629</td>\n",
       "      <td>0.632827</td>\n",
       "      <td>0.810383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>0.872377</td>\n",
       "      <td>0.453942</td>\n",
       "      <td>0.338837</td>\n",
       "      <td>0.146103</td>\n",
       "      <td>0.242241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>0.342356</td>\n",
       "      <td>0.785375</td>\n",
       "      <td>0.321433</td>\n",
       "      <td>0.028890</td>\n",
       "      <td>0.935469</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           x1        x2        x3        x4        x5\n",
       "0    0.497617  0.527752  0.798323  0.640089  0.647731\n",
       "1    0.535168  0.850855  0.434027  0.043455  0.941754\n",
       "2    0.961584  0.858934  0.537252  0.673542  0.737137\n",
       "3    0.372617  0.081365  0.926203  0.853181  0.240759\n",
       "4    0.508953  0.706298  0.066575  0.465725  0.265353\n",
       "..        ...       ...       ...       ...       ...\n",
       "995  0.982321  0.107887  0.367223  0.103049  0.685719\n",
       "996  0.711992  0.306617  0.421300  0.709578  0.532664\n",
       "997  0.489310  0.107751  0.043629  0.632827  0.810383\n",
       "998  0.872377  0.453942  0.338837  0.146103  0.242241\n",
       "999  0.342356  0.785375  0.321433  0.028890  0.935469\n",
       "\n",
       "[1000 rows x 5 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['x1','x2','x3','x4','x5']\n",
    "\n",
    "df = pd.DataFrame(rand_array, columns = cols)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87278dc3-8643-4454-99e2-8b6e830958dc",
   "metadata": {},
   "source": [
    "* **(5 points)** Shuffle the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "52e929a5-9825-49dc-930d-70b11fc52006",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>667</th>\n",
       "      <td>0.641439</td>\n",
       "      <td>0.136382</td>\n",
       "      <td>0.448545</td>\n",
       "      <td>0.542787</td>\n",
       "      <td>0.618749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>760</th>\n",
       "      <td>0.600568</td>\n",
       "      <td>0.444317</td>\n",
       "      <td>0.599178</td>\n",
       "      <td>0.386357</td>\n",
       "      <td>0.078151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625</th>\n",
       "      <td>0.262460</td>\n",
       "      <td>0.625121</td>\n",
       "      <td>0.605669</td>\n",
       "      <td>0.343264</td>\n",
       "      <td>0.972562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>0.871563</td>\n",
       "      <td>0.504950</td>\n",
       "      <td>0.083884</td>\n",
       "      <td>0.714540</td>\n",
       "      <td>0.339843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>0.489310</td>\n",
       "      <td>0.107751</td>\n",
       "      <td>0.043629</td>\n",
       "      <td>0.632827</td>\n",
       "      <td>0.810383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>0.328478</td>\n",
       "      <td>0.133295</td>\n",
       "      <td>0.010622</td>\n",
       "      <td>0.194639</td>\n",
       "      <td>0.042911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.508953</td>\n",
       "      <td>0.706298</td>\n",
       "      <td>0.066575</td>\n",
       "      <td>0.465725</td>\n",
       "      <td>0.265353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>0.776734</td>\n",
       "      <td>0.153550</td>\n",
       "      <td>0.237214</td>\n",
       "      <td>0.726196</td>\n",
       "      <td>0.517286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>854</th>\n",
       "      <td>0.744596</td>\n",
       "      <td>0.837255</td>\n",
       "      <td>0.848914</td>\n",
       "      <td>0.310851</td>\n",
       "      <td>0.456226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>0.967611</td>\n",
       "      <td>0.614773</td>\n",
       "      <td>0.907048</td>\n",
       "      <td>0.602032</td>\n",
       "      <td>0.539495</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           x1        x2        x3        x4        x5\n",
       "667  0.641439  0.136382  0.448545  0.542787  0.618749\n",
       "760  0.600568  0.444317  0.599178  0.386357  0.078151\n",
       "625  0.262460  0.625121  0.605669  0.343264  0.972562\n",
       "386  0.871563  0.504950  0.083884  0.714540  0.339843\n",
       "997  0.489310  0.107751  0.043629  0.632827  0.810383\n",
       "..        ...       ...       ...       ...       ...\n",
       "477  0.328478  0.133295  0.010622  0.194639  0.042911\n",
       "4    0.508953  0.706298  0.066575  0.465725  0.265353\n",
       "362  0.776734  0.153550  0.237214  0.726196  0.517286\n",
       "854  0.744596  0.837255  0.848914  0.310851  0.456226\n",
       "418  0.967611  0.614773  0.907048  0.602032  0.539495\n",
       "\n",
       "[1000 rows x 5 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.sample(frac=1) #shuffle = randomly sample 100% of rows\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0481905e-de53-403f-9bfe-af2a978a3914",
   "metadata": {},
   "source": [
    "* **(7 points)** Break it using a 60/25/15 split into three dataframes: training, validation, and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "39ec8ea5-7f99-4a4a-84b4-f4903ed8499b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(600, 5)\n",
      "(250, 5)\n",
      "(150, 5)\n"
     ]
    }
   ],
   "source": [
    "#let's just use the indeces from the numpy section with pandas .iloc[] funciton\n",
    "\n",
    "df_train = df.iloc[:train_split]\n",
    "df_valid = df.iloc[train_split:train_split+validation_split]\n",
    "df_test = df.iloc[train_split+validation_split:] #take all lefover rows\n",
    "\n",
    "print(df_train.shape)\n",
    "print(df_valid.shape)\n",
    "print(df_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4e5dc3-f327-4e06-8cb1-bc957032a6b5",
   "metadata": {},
   "source": [
    "* **(6 points)** Standardize every column in the training dataframe by subtracting every column by its mean and dividing the result by its standard deviation. Do the same with validation and test dataframes but using the mean and standard deviation from the training dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fde72d01-205d-4813-b976-f052e0e04fbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           x1        x2        x3        x4        x5\n",
      "667  0.535629 -1.253206 -0.142902  0.147636  0.438735\n",
      "760  0.393882 -0.195935  0.376689 -0.403669 -1.382411\n",
      "625 -0.778740  0.424843  0.399078 -0.555541  1.630649\n",
      "386  1.333741  0.012245 -1.400752  0.752944 -0.500833\n",
      "997  0.008019 -1.351508 -1.539610  0.464963  1.084303\n",
      "..        ...       ...       ...       ...       ...\n",
      "170  1.527630 -0.041279  0.966325 -1.215357 -0.352668\n",
      "292 -1.005852  0.302936  0.347231  1.075111 -1.321508\n",
      "181 -0.682129 -1.202935 -1.309097  0.095450  1.207896\n",
      "817 -0.529049 -0.359988  1.117836  0.609706 -1.101763\n",
      "439  0.377032 -0.995760 -0.067774  0.877296  1.241674\n",
      "\n",
      "[600 rows x 5 columns]\n",
      "\n",
      "           x1        x2        x3        x4        x5\n",
      "982 -0.599287  1.412647 -1.526151  1.552813 -0.658049\n",
      "542  0.431182 -0.773982  1.663097 -0.818627  0.102635\n",
      "141 -1.623644  1.654492  1.426498 -1.764206 -1.630122\n",
      "831  1.422164  0.353817  0.305176  0.272197 -0.435401\n",
      "402 -1.325200 -0.808654  1.364460  0.104066 -0.850888\n",
      "..        ...       ...       ...       ...       ...\n",
      "255 -0.626917  0.226397 -0.329159 -0.656731 -0.677826\n",
      "977  0.576457 -1.357503  0.655717 -1.132243 -0.970862\n",
      "755  0.444399  0.301004  1.062711 -1.457623 -1.345265\n",
      "150 -0.611303  1.109267  0.939009 -0.343330 -1.076754\n",
      "87  -1.675990 -1.031030  0.784868  0.093824 -0.519123\n",
      "\n",
      "[250 rows x 5 columns]\n",
      "\n",
      "           x1        x2        x3        x4        x5\n",
      "135 -1.048062 -0.656760  0.497979  1.176303 -1.494883\n",
      "124 -0.257922 -0.671398  0.518870 -1.141359 -0.492341\n",
      "475 -0.160447 -0.403113 -1.270515 -1.004361 -0.062770\n",
      "256  0.487130 -0.132247  0.000661  1.453869 -1.465668\n",
      "559  1.343863  1.671680 -0.013102 -1.676739  0.560245\n",
      "..        ...       ...       ...       ...       ...\n",
      "477 -0.549777 -1.263805 -1.653463 -1.079337 -1.501126\n",
      "4    0.076143  0.703559 -1.460459 -0.123952 -0.751771\n",
      "362  1.004856 -1.194261 -0.871861  0.794024  0.096930\n",
      "854  0.893395  1.153188  1.238124 -0.669773 -0.108765\n",
      "418  1.666853  0.389314  1.438650  0.356434  0.171750\n",
      "\n",
      "[150 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "#save these values for use in validation and test\n",
    "train_mean = df_train.mean() #one row per column\n",
    "train_std = df_train.std()\n",
    "\n",
    "#full array transformation\n",
    "df_train = (df_train-train_mean)/train_std \n",
    "df_valid = (df_valid-train_mean)/train_std \n",
    "df_test = (df_test-train_mean)/train_std \n",
    "\n",
    "print(df_train)\n",
    "print()\n",
    "print(df_valid)\n",
    "print()\n",
    "print(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435685ef-3b08-4fcc-9354-f0dafcbd7136",
   "metadata": {},
   "source": [
    "* **(4 points)** Save all three dataframes into their own `.csv` files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3fc520fa-5ae8-460a-a308-9185f235defc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train.to_csv('output\\\\df_train.csv')\n",
    "df_valid.to_csv('output\\\\df_valid.csv')\n",
    "df_test.to_csv('output\\\\df_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025bd929-25cc-4e99-b885-364ed5b0d42a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## PART D - Matplotlib\n",
    "\n",
    "* **(27 points)** Plot the following functions using $3\\ by\\ 2$ subplots. Each plot must have its own title, and its own x and y labels. Make also sure that each plot enough of the function to show its behavior.\n",
    "    * $f(x) = 3 x^2 + 10$\n",
    "    * $f(x) = \\frac{1}{1 + e^{-x}}$\n",
    "    * $f(z) = max(\\alpha z, z)$ where $\\alpha = 0.01$\n",
    "    * $f(x) = sin(x^2)$\n",
    "    * $f(x) = cos(x) + ln(x)$\n",
    "    * $f(x) = tanh(x)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e28391-fb49-40ee-9bd8-1c56e2a95c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "titles = [\n",
    "    \"Funciton A\", \"Funciton B\", \"Funciton C\", \n",
    "    \"Funciton D\", \"Funciton E\", \"Funciton F\"\n",
    "]\n",
    "\n",
    "x_s = [ \n",
    "    np.arange(-12, 12, .1), np.arange(-5, 5, .1), \n",
    "    np.arange(-6, 6, .1), np.arange(-7, 7, .1),np.arange(1, 7, .1),np.arange(-7, 7, .1)\n",
    "]\n",
    "\n",
    "f_x = [\n",
    "    lambda x: 3 * x**2 + 10,\n",
    "    lambda x: 1 / (1 + np.exp(-x)),\n",
    "    lambda z: np.maximum(.1 * z, z),\n",
    "    lambda x: np.sin(x**2),\n",
    "    lambda x: np.cos(x) + np.log(x),\n",
    "    lambda x: np.tanh(x)\n",
    "]\n",
    "\n",
    "fig = plt.figure(figsize=(16, 15))\n",
    "for i, (x, fx) in enumerate(zip(x_s, f_x)):\n",
    "    plt.subplot(3, 2,i + 1)\n",
    "    plt.plot(x, fx(x))\n",
    "    plt.xlabel(\"$x$\")\n",
    "    plt.ylabel(\"$f(x)$\")\n",
    "    plt.title(titles[i])\n",
    "    plt.grid()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71fa4630-fd25-4837-a722-d9b4ba985665",
   "metadata": {},
   "source": [
    "* **(3 points)** Save the plot into a file named `e01_3by2-fcns.png`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f379f6-8e45-47ed-a015-26ec8d030140",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig('output\\\\e01_3by2-fcns.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
